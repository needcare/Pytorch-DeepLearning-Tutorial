{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_with_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZuG-c3AGwxv"
      },
      "source": [
        "# What is Recurring in Maths ?\n",
        "- Recurring in Maths is simply the repettition of a decimal or an expression.\n",
        "- A recurrence relation is an equation that defines a sequence based on a rule that gives the next term as a function of the previous term(s).\n",
        "- The simplest form of a recurrence relation is the case where the next term depends only on the immediately previous term.\n",
        "\n",
        "# Recurrent Neural Networks(RNN) in Deep Learning.\n",
        "- Recurrent Neural Networks (RNN) are a class of Artificial Neural Networks that can process a sequence of inputs in deep learning and retain its state while processing the next sequence of inputs.\n",
        "- Traditional neural networks will process an input and move onto the next one disregarding its sequence.\n",
        "\n",
        "# **How RNN works:**\n",
        "- <img src=\"https://www.simplilearn.com/ice9/free_resources_article_thumb/Fully_connected_Recurrent_Neural_Network.gif\" width=\"800\" height=\"350\">\n",
        "- It uses previous information to affect later ones.\n",
        "-There are 3 layers: **Input(x), Hidden(h) and output(y).**\n",
        "- In forward step when an input is recieved into the cell it gets multiplied by an **initialized weight** and then it is been **sent as an output** and then **used as an input in the next neuron**.\n",
        "- Let us visualize it using a cell level diagram.\n",
        "- <img src=\"https://blog.floydhub.com/content/images/2019/06/ezgif.com-video-to-gif.gif\" width=\"500\" height=\"350\">\n",
        "- The output of other neurons gets weight initialization as well. Except the first neuron of each layer all other neurons get inputs from **two ends 1) from the previous neuron and 2) other as an input** i.e., next element in the data.\n",
        "- This is how any current neuron will have info of its current and previous data simultaneously.\n",
        "- *The loop*: passes the input forward sequentialy, while re